{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Simple AI Agent Evaluation Lab\n",
    "\n",
    "Welcome! In this lab, you'll learn how to evaluate AI agents using IBM's Granite model. We'll keep things simple and focus on the basics.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to connect to an AI model\n",
    "2. How to create and use simple tools\n",
    "3. How to evaluate AI responses\n",
    "\n",
    "Let's start by installing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install replicate python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the libraries we need and set up our connection to the Granite model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import replicate\n",
    "import json\n",
    "\n",
    "# Enter your Replicate API token\n",
    "api_token = input('Enter your Replicate API token: ')\n",
    "os.environ['REPLICATE_API_TOKEN'] = api_token\n",
    "\n",
    "# Initialize the Granite model\n",
    "client = replicate.Client(api_token=api_token)\n",
    "model = client.models.get(\"ibm-granite/granite-3.3-8b-instruct\")\n",
    "\n",
    "print('âœ… Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Tools\n",
    "\n",
    "Now let's create some simple tools that our AI agent can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class SimpleAgent:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize our simple agent with basic tools\"\"\"\n",
    "        # Weather data (simulated)\n",
    "        self.weather_data = {\n",
    "            \"new york\": \"Sunny, 72Â°F\",\n",
    "            \"london\": \"Cloudy, 65Â°F\",\n",
    "            \"tokyo\": \"Rainy, 68Â°F\",\n",
    "            \"paris\": \"Clear, 70Â°F\"\n",
    "        }\n",
    "    \n",
    "    def use_calculator(self, expression: str) -> str:\n",
    "        \"\"\"Simple calculator tool\"\"\"\n",
    "        try:\n",
    "            # Only allow basic math operations\n",
    "            allowed = set('0123456789+-*/.() ')\n",
    "            if not all(c in allowed for c in expression):\n",
    "                return \"Error: Only basic math operations allowed\"\n",
    "            result = eval(expression)\n",
    "            return f\"The result of {expression} is {result}\"\n",
    "        except:\n",
    "            return \"Error: Could not calculate\"\n",
    "    \n",
    "    def check_weather(self, city: str) -> str:\n",
    "        \"\"\"Simple weather lookup tool\"\"\"\n",
    "        return self.weather_data.get(city.lower(), \"Weather data not available\")\n",
    "    \n",
    "    def analyze_text(self, text: str) -> str:\n",
    "        \"\"\"Simple text analysis tool\"\"\"\n",
    "        words = text.lower().split()\n",
    "        positive = {'good', 'great', 'excellent', 'happy'}\n",
    "        negative = {'bad', 'poor', 'terrible', 'sad'}\n",
    "        \n",
    "        pos_count = sum(1 for w in words if w in positive)\n",
    "        neg_count = sum(1 for w in words if w in negative)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            return \"Positive sentiment detected\"\n",
    "        elif neg_count > pos_count:\n",
    "            return \"Negative sentiment detected\"\n",
    "        else:\n",
    "            return \"Neutral sentiment detected\"\n",
    "\n",
    "# Create our agent\n",
    "agent = SimpleAgent()\n",
    "\n",
    "# Test the tools\n",
    "print(\"Calculator Test:\", agent.use_calculator(\"2 + 2\"))\n",
    "print(\"Weather Test:\", agent.check_weather(\"London\"))\n",
    "print(\"Text Analysis Test:\", agent.analyze_text(\"This is a great day!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Function\n",
    "\n",
    "Let's create a simple function to evaluate our agent's responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_response(query: str, tool_used: str, response: str) -> dict:\n",
    "    \"\"\"Evaluate an agent's response using the Granite model\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"<think>\n",
    "Please evaluate this AI agent interaction:\n",
    "\n",
    "User Query: {query}\n",
    "Tool Used: {tool_used}\n",
    "Agent Response: {response}\n",
    "\n",
    "Rate on a scale of 1-5 (5 being best) and provide a brief explanation.\n",
    "Return your evaluation in this JSON format:\n",
    "{{\"score\": <1-5>, \"explanation\": \"<your brief explanation>\"}}\n",
    "</think>\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Get evaluation from Granite\n",
    "        result = model.predict(prompt, max_new_tokens=200)\n",
    "        return json.loads(result.strip())\n",
    "    except:\n",
    "        return {\"score\": 0, \"explanation\": \"Evaluation failed\"}\n",
    "\n",
    "# Test the evaluation\n",
    "test_query = \"What's 5 plus 3?\"\n",
    "test_response = agent.use_calculator(\"5 + 3\")\n",
    "eval_result = evaluate_response(test_query, \"calculator\", test_response)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Response: {test_response}\")\n",
    "print(f\"Evaluation Score: {eval_result['score']}/5\")\n",
    "print(f\"Explanation: {eval_result['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Try It Yourself!\n",
    "\n",
    "Now you can try different queries and evaluate the responses. Here's an example to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def try_agent(query: str, tool: str, input_value: str):\n",
    "    \"\"\"Test the agent with different queries\"\"\"\n",
    "    # Get the right tool function\n",
    "    if tool == \"calculator\":\n",
    "        response = agent.use_calculator(input_value)\n",
    "    elif tool == \"weather\":\n",
    "        response = agent.check_weather(input_value)\n",
    "    elif tool == \"text\":\n",
    "        response = agent.analyze_text(input_value)\n",
    "    else:\n",
    "        return \"Unknown tool\"\n",
    "    \n",
    "    # Evaluate the response\n",
    "    evaluation = evaluate_response(query, tool, response)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Tool Used: {tool}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Evaluation Score: {evaluation['score']}/5\")\n",
    "    print(f\"Feedback: {evaluation['explanation']}\")\n",
    "\n",
    "# Example usage:\n",
    "print(\"Example 1: Calculator\")\n",
    "try_agent(\"What's 10 times 5?\", \"calculator\", \"10 * 5\")\n",
    "\n",
    "print(\"\\nExample 2: Weather\")\n",
    "try_agent(\"What's the weather in Tokyo?\", \"weather\", \"Tokyo\")\n",
    "\n",
    "print(\"\\nExample 3: Text Analysis\")\n",
    "try_agent(\"How does this text sound?\", \"text\", \"This is a great and wonderful day!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!\n",
    "\n",
    "Try creating your own queries below. Here are some ideas:\n",
    "- Try different calculations\n",
    "- Check weather for different cities\n",
    "- Analyze different text samples\n",
    "\n",
    "Just copy and modify the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your tests here!\n",
    "try_agent(\n",
    "    query=\"What's 25 divided by 5?\",  # Your question\n",
    "    tool=\"calculator\",                # Choose: calculator, weather, or text\n",
    "    input_value=\"25 / 5\"             # Your input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've completed the simple AI agent evaluation lab! You've learned:\n",
    "- How to work with a simple AI agent\n",
    "- How to use different tools\n",
    "- How to evaluate AI responses\n",
    "\n",
    "Feel free to experiment with different queries and tools!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
